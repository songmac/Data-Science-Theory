{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/songmac/2023-Data-Analysis-Study-Personal/blob/master/04_%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D_%EC%9D%B4%EB%A1%A0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rkX66EP2kWA"
      },
      "source": [
        "# <핀테크 머신러닝 이론 및 실습>\n",
        "- 합성데이터: 데이터 신뢰성에 문제가 있음\n",
        "- 금융데이터: 개인정보, 기밀정보 이슈로 대체 데이터 많이 사용\n",
        "- 데이터마이닝: 기계가 학습의 주체가 됨\n",
        "- 머신러닝(비즈니스 문제 해결): 명시적으로 지시를 내리지 않고 데이터로 학습하여 사람이 효율적인 task/test를 수행  ex. transformer model\n",
        "- 딥러닝: 머신러닝의 일부, 뉴럴 네트워크 사용"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "## 1. 머신러닝 종류\n",
        "### 1-1. 지도학습(Supervised Learning)\n",
        "- Label이 있는 데이터셋\n",
        "- 회귀(Regression): 연속적인 변수 예측\n",
        "- 분류(Classification): 범주형 변수 예측\n",
        "\n",
        "### 1-2. 비지도학습(Unsupervised Learning)\n",
        "- Label이 없는 데이터셋\n",
        "- 군집화(Clustering): 그룹으로 세분화 ex. 수입에 따른 직업 군집화\n",
        "- 차원축소(Dimensionality Reduction): 상관관계가 있는 여러 특성을 하나로 합침\n",
        "\n",
        "### 1-3. 준지도학습(Semisupervised Learning)\n",
        "- 지도학습+비지도학습\n",
        "- 일부분 라벨링 필요, 비용발생\n",
        "\n",
        "### 1-4. 강화학습(Reinforcement Learning) ex. 알파고\n",
        "- 마르코프 결정과정 : 보상(reward)/패널티(penalty)를 주어 큰 보상을 얻기위한 policy를 채택하기 위해 학습\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## 2. 머신러닝 알고리즘 개념\n",
        "- 회귀, 분류, 군집화, 차원축소 등\n",
        "- 전처리 : 일부 데이터(training, validation 데이터)로 모델링 후 그 외 test \n",
        "- 데이터로 최종 확인. input 시 data를 random.shuffle하여 주입식 학습 방지하는 것이 좋음. 또한 test 결과에서 스케일을 조정 및 표준화가 필요\n",
        "- fit(학습), transform(예측), score(평가) 함수 사용\n",
        "\n",
        "### 2-1. 알고리즘 - 회귀형\n",
        "- 산점도와 방정식을 통해 함수와 변수의 관계를 학습\n",
        "\n",
        "### 2-2. 알고리즘 - 분류형\n",
        "- KNN (K-Neartest Neighbor, sklearn이용) : 인접 벡터 개수 설정 후 다수결로 결정. 데이터에 대한 라벨링 진행\n",
        "\n",
        "### 2-3. 알고리즘 - 군집화\n",
        "- KMeans 클래스 : 군집화 하며, centric point(평균, 분산  이용)에 점점 가까워지도록 K개수를 지정하여 클러스터링 하는 것. K의 산술적 최적화에 따라 결과 상이\n",
        "\n",
        "### 2-4. 알고리즘 - 차원 축소\n",
        "- 다차원 데이터(1D->2D->3D)는 공간 활용도가 낮아져 차원 축소가 필요. 축소시 정보 손실(가려서 안보이는 것을) 최소화 할 수 있는 축을 찾는 것이 핵심.\n",
        "- PCA(주성분 분석, Principal compoenent analysis) : 고차원의 데이터를 저차원 데이터로 환원시키는 기법. 데이터를 한개의 축으로 사상시켰을 때 그 분산이 가장 커지는 축을 주성분으로하여 선형 변환하고 이를 여러번 반복하여 n개 축을 생성\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## 3. 문서분류(NBC)의 분류 모델\n",
        "### 3-1. 베이즈 분류기(Bayew Classifier)\n",
        "- 범주형 자료에만 적용 가능하며 조건부 확률에 기반한 분류 방법. 수치형은 범주형으로 전환 필요\n",
        "- 확률 P(A) = A(사건발생)/S(표본공간). 즉, counting하는 것\n",
        "- 조건부확률(P(B|A) : 표본공간 S가 A로 변경, 사건 발생이 A,B 교집합으로 변경\n",
        "- 나이브 베이즈 분류 : 범주형 변수 처리, 성능 좋고 많은 데이터 필요, '0' 계산 방지를 위한 Laplace smoothing(분모, 분자에 상수 더함) 또는 로그로 언더플로우('0'으로 수렴) 개선\n",
        "- 베이즈 정리 : 사전-사후 확률 사이의 관계를 조건부 확률을 이용해 계산"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyNmpwQmgob2evoFAhNbXLcQ",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
